{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from IPython import display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense \n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See: https://www.analyticsvidhya.com/blog/2021/04/generate-your-own-dataset-using-gan/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will generate 96px square images.\n"
     ]
    }
   ],
   "source": [
    "GENERATE_RES = 3 # Generation resolution factor \n",
    "# (1=32, 2=64, 3=96, 4=128, etc.)\n",
    "GENERATE_SQUARE = 32 * GENERATE_RES # rows/cols (should be square)\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "# Preview image \n",
    "PREVIEW_ROWS = 4\n",
    "PREVIEW_COLS = 7\n",
    "PREVIEW_MARGIN = 16\n",
    "\n",
    "# Size vector to generate images from\n",
    "SEED_SIZE = 100\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = (r\"C:\\Users\\neham\\Downloads\\Year 4\\ProjectCodingFiles\\GANsPractice\\animals\\animals\\cow\")\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 60000\n",
    "\n",
    "print(f\"Will generate {GENERATE_SQUARE}px square images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2028 files belonging to 90 classes.\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n"
     ]
    }
   ],
   "source": [
    "#train_images = np.load(r\"C:\\Users\\neham\\Downloads\\Year 4\\ProjectCodingFiles\\GANsPractice\\animals\\animals\\cow\")\n",
    "\n",
    "train_images = tf.keras.preprocessing.image_dataset_from_directory(r\"C:\\Users\\neham\\Downloads\\Year 4\\ProjectCodingFiles\\GANsPractice\\animals\\animals\")\n",
    "class_names = train_images.class_names\n",
    "print(type(train_images))\n",
    "#train_images = train_images.reshape(train_images.shape[0],28,28,1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BatchDataset' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-365f87307c61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m127.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m127.5\u001b[0m  \u001b[1;31m# Normalize the images to [-1, 1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mBUFFER_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m60000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BatchDataset' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
    "\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_GeneratorState',\n",
       " '__abstractmethods__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_apply_options',\n",
       " '_as_serialized_graph',\n",
       " '_batch_size',\n",
       " '_checkpoint_dependencies',\n",
       " '_consumers',\n",
       " '_deferred_dependencies',\n",
       " '_drop_remainder',\n",
       " '_flat_shapes',\n",
       " '_flat_structure',\n",
       " '_flat_types',\n",
       " '_functions',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_graph',\n",
       " '_graph_attr',\n",
       " '_handle_deferred_dependencies',\n",
       " '_has_captured_ref',\n",
       " '_input_dataset',\n",
       " '_inputs',\n",
       " '_list_extra_dependencies_for_serialization',\n",
       " '_list_functions_for_serialization',\n",
       " '_lookup_dependency',\n",
       " '_map_resources',\n",
       " '_maybe_initialize_trackable',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_no_dependency',\n",
       " '_object_identifier',\n",
       " '_options',\n",
       " '_options_attr',\n",
       " '_options_tensor_to_options',\n",
       " '_preload_simple_restoration',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_self_name_based_restores',\n",
       " '_self_saveable_object_factories',\n",
       " '_self_setattr_tracking',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_setattr_tracking',\n",
       " '_shape_invariant_to_type_spec',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_structure',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_trace_variant_creation',\n",
       " '_track_trackable',\n",
       " '_tracking_metadata',\n",
       " '_type_spec',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_update_uid',\n",
       " '_variant_tensor',\n",
       " '_variant_tensor_attr',\n",
       " '_variant_tracker',\n",
       " 'apply',\n",
       " 'as_numpy_iterator',\n",
       " 'batch',\n",
       " 'cache',\n",
       " 'cardinality',\n",
       " 'class_names',\n",
       " 'concatenate',\n",
       " 'element_spec',\n",
       " 'enumerate',\n",
       " 'file_paths',\n",
       " 'filter',\n",
       " 'flat_map',\n",
       " 'from_generator',\n",
       " 'from_tensor_slices',\n",
       " 'from_tensors',\n",
       " 'interleave',\n",
       " 'list_files',\n",
       " 'map',\n",
       " 'options',\n",
       " 'padded_batch',\n",
       " 'prefetch',\n",
       " 'range',\n",
       " 'reduce',\n",
       " 'repeat',\n",
       " 'shard',\n",
       " 'shuffle',\n",
       " 'skip',\n",
       " 'take',\n",
       " 'unbatch',\n",
       " 'window',\n",
       " 'with_options',\n",
       " 'zip']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(train_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
